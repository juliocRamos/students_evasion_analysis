{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "from sklearn.metrics import make_scorer, confusion_matrix, classification_report, accuracy_score, \\\n",
    "                            roc_auc_score, precision_score, f1_score, recall_score, \\\n",
    "                            mean_squared_error, mean_absolute_error, max_error, log_loss\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "from tensorflow.python.keras.utils.vis_utils import plot_model\n",
    "from tensorflow.python.keras.layers import Dense, Dropout\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras import Sequential\n",
    "from sklearn.pipeline import Pipeline\n",
    "from tensorflow.keras import metrics\n",
    "from datetime import timedelta\n",
    "import tensorflow as tf\n",
    "from time import time\n",
    "import pandas as pd\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change flag to run local or in colab\n",
    "colab_env = False\n",
    "\n",
    "results_dir = \"\"\n",
    "model = \"neural_network\"\n",
    "if colab_env:\n",
    "    # default to run in colab\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "\n",
    "    sys.path.insert(1, \"/content/drive/Shareddrives/tcc_pos/utils\")\n",
    "    import model_utils\n",
    "\n",
    "    results_dir = \"/content/drive/Shareddrives/tcc_pos/results_/\"\n",
    "    dataframe_path = \"/content/drive/Shareddrives/tcc_pos/datasets/no_filtered_analysis.csv\"   \n",
    "else:\n",
    "    # default to run local\n",
    "    dataframe_path = \"../../pre_processing/datasets/preprocessed_data/no_filtered.csv\"\n",
    "\n",
    "    sys.path.insert(1, \"../../utils/\")\n",
    "    import model_utils\n",
    "\n",
    "    results_dir = \"./\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(dataframe_path, sep = \",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop RA column if exists\n",
    "if \"RA\" in df.columns:\n",
    "    print(\"Removing column RA\")\n",
    "    df.drop('RA', inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configurate neural network features (layers, layer density, etc)\n",
    "input_dim = len(df.iloc[:, df.columns != \"EVADIDO\"].columns)\n",
    "def create_model(optimizer=\"adam\", dropout=0.2, init='uniform', input_dim=input_dim):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(units=8, input_dim=input_dim, activation='relu'))\n",
    "    model.add(Dropout(rate = dropout))\n",
    "    model.add(Dense(units=8, input_dim=input_dim, activation='relu'))\n",
    "    model.add(Dropout(rate = dropout))\n",
    "    model.add(Dense(units=2, activation='softmax'))\n",
    "\n",
    "    adam = tf.keras.optimizers.Adam(lr=0.01)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer = adam, metrics=[\n",
    "        \"acc\",\n",
    "        \"mse\",\n",
    "        metrics.Precision(),\n",
    "        metrics.Recall(),\n",
    "    ])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_prediction (X_train, X_test, y_train, y_test, splits, input_dim):\n",
    "    \n",
    "    # used to evaluate best model params\n",
    "    gridsearch_metrics = {\n",
    "        'accuracy': 'accuracy',\n",
    "        'rec':'recall', \n",
    "        'auc':'roc_auc', \n",
    "        'f1': 'f1',\n",
    "        'precision': 'precision',\n",
    "        'mse': 'neg_mean_squared_error',\n",
    "        'mae': 'neg_mean_absolute_error'\n",
    "    }\n",
    "    \n",
    "    # define the grid search parameters\n",
    "    param_grid = {\n",
    "        'clf__epochs': [10, 50, 100],\n",
    "        'clf__init': [ 'uniform', 'normal' ],\n",
    "        'clf__batch_size':[50],\n",
    "        'clf__optimizer':['RMSprop', 'Adam', 'Adamax', 'sgd'],\n",
    "        'clf__dropout': [0.3, 0.2, 0.1, 0]\n",
    "    }\n",
    "    \n",
    "    kears_estimator = KerasClassifier(build_fn=create_model, verbose=2)\n",
    "    model_pipeline = Pipeline([(\"scl\", StandardScaler()),\n",
    "                               (\"clf\", kears_estimator)])\n",
    "\n",
    "    clf = GridSearchCV(estimator=model_pipeline,  \n",
    "                    n_jobs= 4,\n",
    "                    verbose= 1,\n",
    "                    cv = StratifiedKFold(n_splits = splits),\n",
    "                    return_train_score=True,\n",
    "                    param_grid = param_grid,\n",
    "                    #scoring = gridsearch_metrics,\n",
    "                    refit = 'accuracy')\n",
    "    \n",
    "    ## GridSearch with best params\n",
    "    start_time = time()\n",
    "    clf.fit(X_train, y_train)\n",
    "    predictions = clf.predict(X_test)\n",
    "    end_time = time()\n",
    "    total_time = timedelta(seconds=end_time-start_time)\n",
    "    best_param = clf.best_params_\n",
    "    \n",
    "    ## Prediction data\n",
    "    predict_data = {\n",
    "        \"database\": \"\",\n",
    "        \"n_splits\": n_splits,\n",
    "        \"confusion_matrix\": confusion_matrix(y_test, predictions, labels=np.unique(predictions)),\n",
    "        \"classification_report\": classification_report(y_test, predictions),\n",
    "        \"model_accuracy\": accuracy_score(y_test, predictions),\n",
    "        \"f1_score\": f1_score(y_test, predictions, labels=np.unique(predictions)),\n",
    "        \"precision_score\": precision_score(y_test, predictions),\n",
    "        \"roc_score\": roc_auc_score(y_test, predictions),\n",
    "        \"recall_score\": recall_score(y_test, predictions),\n",
    "        \"log_loss\": log_loss(y_test, predictions),\n",
    "        \"epoch_params\": best_param,\n",
    "        \"mean_squared_error\": mean_squared_error(y_test, predictions),\n",
    "        \"mean_absolute_error\": mean_absolute_error(y_test, predictions),\n",
    "        \"train_test_duration\": total_time,\n",
    "        \"train_size\": \"uniform\",\n",
    "        \"train_size\": len(X_train),\n",
    "        \"test_size\": len(X_test)\n",
    "    }\n",
    "\n",
    "    return predict_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    X = df.iloc[:, df.columns != \"EVADIDO\"].values\n",
    "    y = df[\"EVADIDO\"]\n",
    "\n",
    "    all_predictions = []\n",
    "    max_splits = 10\n",
    "    n_runs = 10\n",
    "    X_train, X_test, y_train, y_test \\\n",
    "        = train_test_split(X, y, test_size=0.33, random_state=42, stratify = y)\n",
    "\n",
    "    for run in range(n_runs):\n",
    "        print(f\"Running {run+1} of {n_runs} \\n\\n\")\n",
    "        for split in range(2, max_splits, 2):\n",
    "            print(f\"\\nStratifiedKFold config: {split} \\n\")\n",
    "\n",
    "            # return best k element\n",
    "            all_predictions.append(run_prediction(X_train, X_test, y_train, y_test, split))\n",
    "\n",
    "        # General model outputs\n",
    "        model_utils.generate_output(all_predictions, results_dir, model, run)\n",
    "        print(f\"############################ FINISHED RUN {run+1} ############################\")\n",
    "\n",
    "    # CSV Output results\n",
    "    model_utils.generate_output_csv(all_predictions, results_dir, model)\n",
    "    print(f\"############################ FINISHED ALL ############################\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
