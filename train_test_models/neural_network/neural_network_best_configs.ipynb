{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "from sklearn.metrics import make_scorer, confusion_matrix, classification_report, accuracy_score, \\\n",
    "                            roc_auc_score, precision_score, f1_score, recall_score, \\\n",
    "                            mean_squared_error, mean_absolute_error, log_loss\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "from tensorflow.python.keras.utils.vis_utils import plot_model\n",
    "from tensorflow.python.keras.layers import Dense, Dropout\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from ast import literal_eval as make_tuple\n",
    "from tensorflow.keras import Sequential\n",
    "from sklearn.pipeline import Pipeline\n",
    "from tensorflow.keras import metrics\n",
    "from datetime import timedelta\n",
    "import tensorflow as tf\n",
    "from time import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.insert(1, \"../../utils/\")\n",
    "import model_utils\n",
    "\n",
    "results_dir = \"./\"\n",
    "best_results_path = \"../grid_search_results/neural_network_params.csv\"\n",
    "best_results = pd.read_csv(best_results_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get best params according to grid_search best params\n",
    "top3_best_params = best_results.nlargest(3,['model_accuracy', 'f1_score', 'roc_score'])\n",
    "top3_best_params.drop_duplicates([\"epoch_best_params\"], inplace = True)\n",
    "\n",
    "# list top 3 results in which epoch_best_params are different\n",
    "top3_best_params.head(3)\n",
    "#print(top3_best_params[\"epoch_best_params\"].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "all_predictions = []\n",
    "for row in top3_best_params.iterrows():\n",
    "    # load correct database in which best results were saved\n",
    "    dbname = row[1][\"database\"]\n",
    "    dataframe_path = f\"../../pre_processing/datasets/preprocessed_data/{dbname}.csv\"\n",
    "    df = pd.read_csv(dataframe_path, sep = \",\")\n",
    "\n",
    "    # Drop RA column if exists\n",
    "    if \"RA\" in df.columns:\n",
    "        print(\"Removing column RA\")\n",
    "        df.drop('RA', inplace=True, axis=1)\n",
    "\n",
    "    X = df.iloc[:, df.columns != \"EVADIDO\"].values\n",
    "    y = df[\"EVADIDO\"]\n",
    "\n",
    "    input_dim = len(df.columns)\n",
    "    input_dim = input_dim - 1\n",
    "    n_splits = row[1][\"n_splits\"]\n",
    "    best_param = row[1][-1] # row with best params\n",
    "    best_param_tuple = make_tuple(best_param)\n",
    "    \n",
    "    epochs = best_param_tuple['clf__epochs']\n",
    "    init = best_param_tuple['clf__init']\n",
    "    batch_size = best_param_tuple['clf__batch_size']\n",
    "    optimizer = best_param_tuple['clf__optimizer']\n",
    "    dropout = best_param_tuple['clf__dropout']\n",
    "\n",
    "    # Apply best params to model to check accuracy\n",
    "    clf = Sequential()\n",
    "    clf.add(Dense(units=8, kernel_initializer= \"uniform\", activation='relu'))\n",
    "    clf.add(Dropout(rate = dropout))\n",
    "    clf.add(Dense(units=8, kernel_initializer= \"uniform\", activation='relu'))\n",
    "    clf.add(Dropout(rate = dropout))\n",
    "    clf.add(Dense(units=2, activation='softmax'))\n",
    "\n",
    "    clf.compile(loss='categorical_crossentropy', optimizer = \"RMSprop\", metrics=[\n",
    "        \"acc\",\n",
    "        \"mse\",\n",
    "        metrics.Precision(),\n",
    "        metrics.Recall(),\n",
    "    ])\n",
    "\n",
    "    estimator = Pipeline([(\"scl\", StandardScaler()),\n",
    "                          (\"clf\", clf)])\n",
    "    \n",
    "    skf = StratifiedKFold(n_splits = n_splits, shuffle = True)\n",
    "\n",
    "    for i in range(1, 11):\n",
    "        for index, (train_index, test_index) in enumerate(skf.split(X, y)):\n",
    "            print(f\"{i}'st run for split {index}\")\n",
    "            X_train, X_test = X[train_index], X[test_index]\n",
    "            y_train, y_test = to_categorical(y[train_index]), to_categorical(y[test_index])\n",
    "\n",
    "            start_time = time()        \n",
    "            estimator.fit(X_train, y_train, clf__epochs = epochs, clf__batch_size = batch_size, clf__verbose = 0)\n",
    "            predictions = estimator.predict(X_test)\n",
    "            end_time = time()\n",
    "            total_time = timedelta(seconds=end_time-start_time)\n",
    "\n",
    "            y_test = y_test.argmax(axis=1)\n",
    "            predictions = predictions.argmax(axis=1)\n",
    "\n",
    "            predict_data = {\n",
    "                \"database\": dbname,\n",
    "                \"n_splits\": n_splits,\n",
    "                \"confusion_matrix\": confusion_matrix(y_test, predictions, labels=np.unique(predictions)),\n",
    "                \"classification_report\": classification_report(y_test, predictions),\n",
    "                \"model_accuracy\": accuracy_score(y_test, predictions),\n",
    "                \"f1_score\": f1_score(y_test, predictions, labels=np.unique(predictions)),\n",
    "                \"precision_score\": precision_score(y_test, predictions),\n",
    "                \"roc_score\": roc_auc_score(y_test, predictions),\n",
    "                \"recall_score\": recall_score(y_test, predictions),\n",
    "                \"log_loss\": log_loss(y_test, predictions),\n",
    "                \"epoch_params\": best_param,\n",
    "                \"mean_squared_error\": mean_squared_error(y_test, predictions),\n",
    "                \"mean_absolute_error\": mean_absolute_error(y_test, predictions),\n",
    "                \"train_test_duration\": total_time,\n",
    "                \"train_size\": \"uniform\",\n",
    "                \"train_size\": len(X_train),\n",
    "                \"test_size\": len(X_test)\n",
    "            }\n",
    "\n",
    "            all_predictions.append(predict_data)\n",
    "\n",
    "# CSV Output results\n",
    "model_utils.generate_output_csv(all_predictions, results_dir, \"neural_network_results\")\n",
    "print(\"FINISHED\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
