{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## IMPORTS\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score, \\\n",
    "                            roc_auc_score, precision_score, f1_score, recall_score, \\\n",
    "                            mean_squared_error, mean_absolute_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from ast import literal_eval as make_tuple\n",
    "from sklearn.pipeline import Pipeline\n",
    "from datetime import timedelta\n",
    "from sklearn.svm import SVC\n",
    "from time import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.insert(1, \"../../utils/\")\n",
    "import model_utils\n",
    "\n",
    "results_dir = \"./\"\n",
    "best_results_path = \"../grid_search_results/svc_params.csv\"\n",
    "best_results = pd.read_csv(best_results_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>database</th>\n",
       "      <th>n_splits</th>\n",
       "      <th>model_accuracy</th>\n",
       "      <th>f1_score</th>\n",
       "      <th>precision_score</th>\n",
       "      <th>roc_score</th>\n",
       "      <th>recall_score</th>\n",
       "      <th>max_error</th>\n",
       "      <th>mean_squared_error</th>\n",
       "      <th>mean_absolute_error</th>\n",
       "      <th>train_test_duration</th>\n",
       "      <th>epoch_best_params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>backward</td>\n",
       "      <td>6</td>\n",
       "      <td>0.934132</td>\n",
       "      <td>0.912</td>\n",
       "      <td>0.982759</td>\n",
       "      <td>0.920373</td>\n",
       "      <td>0.850746</td>\n",
       "      <td>1</td>\n",
       "      <td>0.065868</td>\n",
       "      <td>0.065868</td>\n",
       "      <td>0 days 00:00:07.336496</td>\n",
       "      <td>{'clf__C': 2, 'clf__decision_function_shape': ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   database  n_splits  model_accuracy  f1_score  precision_score  roc_score  \\\n",
       "2  backward         6        0.934132     0.912         0.982759   0.920373   \n",
       "\n",
       "   recall_score  max_error  mean_squared_error  mean_absolute_error  \\\n",
       "2      0.850746          1            0.065868             0.065868   \n",
       "\n",
       "      train_test_duration                                  epoch_best_params  \n",
       "2  0 days 00:00:07.336496  {'clf__C': 2, 'clf__decision_function_shape': ...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get best params according to grid_search best params\n",
    "top3_best_params = best_results.nlargest(3,['model_accuracy', 'f1_score', 'roc_score'])\n",
    "top3_best_params.drop_duplicates([\"epoch_best_params\"], inplace = True)\n",
    "\n",
    "# list top 3 results in which epoch_best_params are different\n",
    "top3_best_params.head(3)\n",
    "#print(top3_best_params[\"epoch_best_params\"].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1'st run for split 0\n",
      "1'st run for split 1\n",
      "1'st run for split 2\n",
      "1'st run for split 3\n",
      "1'st run for split 4\n",
      "1'st run for split 5\n",
      "2'st run for split 0\n",
      "2'st run for split 1\n",
      "2'st run for split 2\n",
      "2'st run for split 3\n",
      "2'st run for split 4\n",
      "2'st run for split 5\n",
      "3'st run for split 0\n",
      "3'st run for split 1\n",
      "3'st run for split 2\n",
      "3'st run for split 3\n",
      "3'st run for split 4\n",
      "3'st run for split 5\n",
      "4'st run for split 0\n",
      "4'st run for split 1\n",
      "4'st run for split 2\n",
      "4'st run for split 3\n",
      "4'st run for split 4\n",
      "4'st run for split 5\n",
      "5'st run for split 0\n",
      "5'st run for split 1\n",
      "5'st run for split 2\n",
      "5'st run for split 3\n",
      "5'st run for split 4\n",
      "5'st run for split 5\n",
      "6'st run for split 0\n",
      "6'st run for split 1\n",
      "6'st run for split 2\n",
      "6'st run for split 3\n",
      "6'st run for split 4\n",
      "6'st run for split 5\n",
      "7'st run for split 0\n",
      "7'st run for split 1\n",
      "7'st run for split 2\n",
      "7'st run for split 3\n",
      "7'st run for split 4\n",
      "7'st run for split 5\n",
      "8'st run for split 0\n",
      "8'st run for split 1\n",
      "8'st run for split 2\n",
      "8'st run for split 3\n",
      "8'st run for split 4\n",
      "8'st run for split 5\n",
      "9'st run for split 0\n",
      "9'st run for split 1\n",
      "9'st run for split 2\n",
      "9'st run for split 3\n",
      "9'st run for split 4\n",
      "9'st run for split 5\n",
      "10'st run for split 0\n",
      "10'st run for split 1\n",
      "10'st run for split 2\n",
      "10'st run for split 3\n",
      "10'st run for split 4\n",
      "10'st run for split 5\n",
      "FINISHED\n"
     ]
    }
   ],
   "source": [
    "all_predictions = []\n",
    "for row in top3_best_params.iterrows():\n",
    "    # load correct database in which best results were saved\n",
    "    dbname = row[1][\"database\"]\n",
    "    dataframe_path = f\"../../pre_processing/datasets/preprocessed_data/{dbname}.csv\"\n",
    "    df = pd.read_csv(dataframe_path, sep = \",\")\n",
    "\n",
    "    # Drop RA column if exists\n",
    "    if \"RA\" in df.columns:\n",
    "        print(\"Removing column RA\")\n",
    "        df.drop('RA', inplace=True, axis=1)\n",
    "\n",
    "    X = df.iloc[:, df.columns != \"EVADIDO\"].values\n",
    "    y = df[\"EVADIDO\"]\n",
    "\n",
    "    input_dim = len(df.columns)\n",
    "    input_dim = input_dim - 1\n",
    "    n_splits = row[1][\"n_splits\"]\n",
    "    best_param = row[1][-1] # row with best params\n",
    "    best_param_tuple = make_tuple(best_param)\n",
    "    \n",
    "    kernel = best_param_tuple['clf__kernel']\n",
    "    c = best_param_tuple['clf__C']\n",
    "    gamma = best_param_tuple['clf__gamma']\n",
    "    decision_function_shape = best_param_tuple['clf__decision_function_shape']\n",
    "    shrinking = best_param_tuple['clf__shrinking']\n",
    "    max_iter = best_param_tuple['clf__max_iter']\n",
    "\n",
    "    # Apply best params to model to check accuracy\n",
    "    clf = SVC(\n",
    "        kernel = kernel,\n",
    "        C = c,\n",
    "        gamma = gamma,\n",
    "        decision_function_shape =  decision_function_shape,\n",
    "        shrinking = shrinking,\n",
    "        max_iter = max_iter\n",
    "    )\n",
    "\n",
    "    estimator = Pipeline([(\"scl\", StandardScaler()),\n",
    "                          (\"clf\", clf)])\n",
    "\n",
    "    skf = StratifiedKFold(n_splits = n_splits, shuffle = True)\n",
    "    for i in range(1, 11):\n",
    "        for index, (train_index, test_index) in enumerate(skf.split(X, y)):\n",
    "            print(f\"{i}'st run for split {index}\")\n",
    "            X_train, X_test = X[train_index], X[test_index]\n",
    "            y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "            start_time = time()\n",
    "            estimator.fit(X_train, y_train)\n",
    "            predictions = estimator.predict(X_test)\n",
    "            end_time = time()\n",
    "            total_time = timedelta(seconds=end_time-start_time)\n",
    "\n",
    "            predict_data = {\n",
    "                \"database\": dbname,\n",
    "                \"n_splits\": f\"{i}_{index}_{n_splits}\",\n",
    "                \"confusion_matrix\": confusion_matrix(y_test, predictions, labels=np.unique(predictions)),\n",
    "                \"classification_report\": classification_report(y_test, predictions),\n",
    "                \"model_accuracy\": accuracy_score(y_test, predictions),\n",
    "                \"f1_score\": f1_score(y_test, predictions, labels=np.unique(predictions)),\n",
    "                \"precision_score\": precision_score(y_test, predictions),\n",
    "                \"roc_score\": roc_auc_score(y_test, predictions),\n",
    "                \"recall_score\": recall_score(y_test, predictions),\n",
    "                \"log_loss\": \"na\",\n",
    "                \"epoch_params\": best_param,\n",
    "                \"mean_squared_error\": mean_squared_error(y_test, predictions),\n",
    "                \"mean_absolute_error\": mean_absolute_error(y_test, predictions),\n",
    "                \"train_test_duration\": total_time,\n",
    "                \"train_size\": \"uniform\",\n",
    "                \"train_size\": len(X_train),\n",
    "                \"test_size\": len(X_test)\n",
    "            }\n",
    "\n",
    "            all_predictions.append(predict_data)\n",
    "\n",
    "# CSV Output results\n",
    "model_utils.generate_output_csv(all_predictions, results_dir, \"svc_results\")\n",
    "print(\"FINISHED\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
