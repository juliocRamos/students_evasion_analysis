{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## imports\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score, \\\n",
    "                            roc_auc_score, precision_score, f1_score, recall_score, \\\n",
    "                            mean_squared_error, mean_absolute_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from ast import literal_eval as make_tuple\n",
    "from sklearn.pipeline import Pipeline\n",
    "from datetime import timedelta\n",
    "from time import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.insert(1, \"../../utils/\")\n",
    "import model_utils\n",
    "\n",
    "results_dir = \"./\"\n",
    "best_results_path = \"../grid_search_results/dtree_params.csv\"\n",
    "best_results = pd.read_csv(best_results_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get best params according to grid_search best params\n",
    "top3_best_params = best_results.nlargest(2,['model_accuracy', 'f1_score', 'roc_score'])\n",
    "top3_best_params.drop_duplicates([\"epoch_best_params\"], inplace = True)\n",
    "\n",
    "# list top 3 results in which epoch_best_params are different\n",
    "top3_best_params.head(3)\n",
    "#print(top3_best_params[\"epoch_best_params\"].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "all_predictions = []\n",
    "for row in top3_best_params.iterrows():\n",
    "    # load correct database in which best results were saved\n",
    "    dbname = row[1][\"database\"]\n",
    "    dataframe_path = f\"../../pre_processing/datasets/preprocessed_data/{dbname}.csv\"\n",
    "    df = pd.read_csv(dataframe_path, sep = \",\")\n",
    "\n",
    "    # Drop RA column if exists\n",
    "    if \"RA\" in df.columns:\n",
    "        print(\"Removing column RA\")\n",
    "        df.drop('RA', inplace=True, axis=1)\n",
    "\n",
    "    X = df.iloc[:, df.columns != \"EVADIDO\"].values\n",
    "    y = df[\"EVADIDO\"]\n",
    "\n",
    "    n_splits = row[1][\"n_splits\"]\n",
    "    best_param = row[1][-1] # row with best params\n",
    "    best_param_tuple = make_tuple(best_param)\n",
    "    criterion = best_param_tuple['clf__criterion']\n",
    "    splitter = best_param_tuple['clf__splitter']\n",
    "    max_depth = best_param_tuple['clf__max_depth']\n",
    "    max_leaf_nodes = best_param_tuple['clf__max_leaf_nodes']\n",
    "    max_features = best_param_tuple['clf__max_features']\n",
    "\n",
    "    # Apply best params to model to check accuracy\n",
    "    clf = DecisionTreeClassifier(\n",
    "        criterion = criterion,\n",
    "        splitter = splitter,\n",
    "        max_depth = max_depth,\n",
    "        max_leaf_nodes =  max_leaf_nodes,\n",
    "        max_features = max_features)\n",
    "\n",
    "    estimator = Pipeline([(\"scl\", StandardScaler()),\n",
    "                          (\"clf\", clf)])\n",
    "    \n",
    "    skf = StratifiedKFold(n_splits = n_splits, shuffle = True)\n",
    "    for i in range(1, 11):\n",
    "        for index, (train_index, test_index) in enumerate(skf.split(X, y)):\n",
    "            print(f\"{i}'st run for split {index}\")\n",
    "            X_train, X_test = X[train_index], X[test_index]\n",
    "            y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "            start_time = time()\n",
    "            estimator.fit(X_train, y_train)\n",
    "            predictions = estimator.predict(X_test)\n",
    "            end_time = time()\n",
    "            total_time = timedelta(seconds=end_time-start_time)\n",
    "\n",
    "            predict_data = {\n",
    "                \"database\": dbname,\n",
    "                \"n_splits\": f\"{i}_{index}_{n_splits}\",\n",
    "                \"confusion_matrix\": confusion_matrix(y_test, predictions),\n",
    "                \"classification_report\": classification_report(y_test, predictions),\n",
    "                \"model_accuracy\": accuracy_score(y_test, predictions),\n",
    "                \"f1_score\": f1_score(y_test, predictions),\n",
    "                \"precision_score\": precision_score(y_test, predictions),\n",
    "                \"roc_score\": roc_auc_score(y_test, predictions),\n",
    "                \"recall_score\": recall_score(y_test, predictions),\n",
    "                \"log_loss\": \"na\",\n",
    "                \"epoch_params\": best_param,\n",
    "                \"mean_squared_error\": mean_squared_error(y_test, predictions),\n",
    "                \"mean_absolute_error\": mean_absolute_error(y_test, predictions),\n",
    "                \"train_test_duration\": total_time,\n",
    "                \"train_size\": len(X_train),\n",
    "                \"test_size\": len(X_test)\n",
    "            }\n",
    "\n",
    "            all_predictions.append(predict_data)\n",
    "\n",
    "\n",
    "# CSV Output results\n",
    "model_utils.generate_output_csv(all_predictions, results_dir, \"dtree_results\")\n",
    "print(\"FINISHED\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
